{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cats vs Dogs redux (kaggle)\n",
    "\n",
    "This code implements a deep learning classification model to distinguish between images of cats and images of dogs. It makes use of the pretrained VGG16 model<sup>1</sup> by using the Python `vgg` class [provided by Fast.AI](https://github.com/fastai/courses/blob/master/deeplearning1/nbs/vgg16.py) as part of the [Practical Deep Learning for Coders](http://course.fast.ai/lessons/lesson1.html) course as well as their [`utils.py`](https://github.com/fastai/courses/blob/master/deeplearning1/nbs/utils.py) package.\n",
    "\n",
    "The code assumes that their is a data folder whose structure is defined in the [Prepare Data](https://github.com/DanGolding/kaggle_cats_vs_dogs_redux/blob/master/Prepare%20data.ipynb) notebook in this repository.\n",
    "\n",
    "<sup>1</sup>K. Simonyan, A. Zisserman [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/pdf/1409.1556.pdf), arXiv technical report, 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline\n",
    "\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "# path = \"data/sample/\"\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      " 4224/23000 [====>.........................] - ETA: 488s - loss: 0.1675 - acc: 0.9583"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()\n",
    "\n",
    "generator = image.ImageDataGenerator()\n",
    "batches = generator.flow_from_directory(path + 'train',target_size=(224,224),batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "val_batches = generator.flow_from_directory(path + 'valid',target_size=(224,224),batch_size=batch_size*2, class_mode='categorical', shuffle=True)\n",
    "\n",
    "# Adapt the model from predicting ImageNet classes to predicting Cats vs Dogs\n",
    "def finetune(model,num_classes,lr):\n",
    "    model.pop()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "    vgg.compile(lr)\n",
    "\n",
    "def fit(model):\n",
    "    hist = model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=1,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "    return hist.history['val_loss'][0]\n",
    "    \n",
    "lr = 0.002\n",
    "finetune(vgg.model,batches.nb_class,lr)\n",
    "tol = 0.005\n",
    "loss_previous = fit(vgg.model)\n",
    "epochs = 5\n",
    "for ep in range(epochs):\n",
    "    print('Epoch {}'.format(ep+1))\n",
    "    loss_current = fit(vgg.model)\n",
    "    print('val_loss decreased by {}%'.format(100*(loss_previous - loss_current)/loss_previous))\n",
    "    if (loss_previous - loss_current)/loss_previous < tol:\n",
    "        lr /= 2.\n",
    "        tol /= 2.\n",
    "        print('lr: {}'.format(lr))\n",
    "        vgg.model.optimizer.lr = lr\n",
    "    loss_previous = loss_current\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.save_weights(path + 'results/ft2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the trained model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = generator.flow_from_directory(path + 'test',target_size=(224,224),batch_size=batch_size*2, class_mode=None, shuffle=False)\n",
    "predictions = vgg.model.predict_generator(test_batches,test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the results for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = test_batches.filenames\n",
    "utils.save_array(path + 'results/test_predictions_II.dat',predictions)\n",
    "utils.save_array(path + 'results/test_filenames_II.dat',filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = np.array([int(filename.split('.')[0].split(\"/\")[1]) for filename in filenames])\n",
    "results = np.vstack((ids,np.clip(predictions,0.05,0.95)[:,1])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the submission file and a link in order to download it to a local machine in order to submit to kaggle via the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(path + 'results/results_II.csv',results,fmt='%d,%.5f',delimiter=',',header='id,label',comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/results/results_II.csv' target='_blank'>data/results/results_II.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/FastAI/courses/deeplearning1/assignments/kaggle_cats_vs_dogs_redux/data/results/results_II.csv"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(path + 'results/results_II.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
